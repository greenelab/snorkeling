{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label The Candidates!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook corresponds to labeling and genearting features for each extracted candidate from the [previous notebook](1.data-loader.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST RUN AT THE START OF EVERYTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the imports and set up the database for database operations. Plus, set up the particular candidate type this notebook is going to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:58.165681Z",
     "start_time": "2018-08-27T21:00:57.814504Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:58.329559Z",
     "start_time": "2018-08-27T21:00:58.167067Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "username = \"danich1\"\n",
    "password = \"snorkel\"\n",
    "dbname = \"pubmeddb\"\n",
    "\n",
    "#Path subject to change for different os\n",
    "database_str = \"postgresql+psycopg2://{}:{}@/{}?host=/var/run/postgresql\".format(username, password, dbname)\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:58.354246Z",
     "start_time": "2018-08-27T21:00:58.331237Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator, LabelAnnotator\n",
    "from snorkel.features import get_span_feats\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.models import Candidate, GoldLabel\n",
    "from snorkel.viewer import SentenceNgramViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:58.367724Z",
     "start_time": "2018-08-27T21:00:58.355716Z"
    }
   },
   "outputs": [],
   "source": [
    "edge_type = \"cg\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:58.390446Z",
     "start_time": "2018-08-27T21:00:58.369634Z"
    }
   },
   "outputs": [],
   "source": [
    "if edge_type == \"dg\":\n",
    "    DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])\n",
    "    edge = \"disease_gene\"\n",
    "elif edge_type == \"gg\":\n",
    "    GeneGene = candidate_subclass('GeneGene', ['Gene1', 'Gene2'])\n",
    "    edge = \"gene_gene\"\n",
    "elif edge_type == \"cg\":\n",
    "    CompoundGene = candidate_subclass('CompoundGene', ['Compound', 'Gene'])\n",
    "    edge = \"compound_gene\"\n",
    "elif edge_type == \"cd\":\n",
    "    CompoundDisease = candidate_subclass('CompoundDisease', ['Compound', 'Disease'])\n",
    "    edge = \"compound_disease\"\n",
    "else:\n",
    "    print(\"Please pick a valid edge type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Label Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at potential Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to look at loaded candidates from a given set. The constants represent the index to retrieve the appropiate set. Ideally, here is where one can look at a subset of the candidate and develop label functions for candidate labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:01:12.988399Z",
     "start_time": "2018-08-27T21:01:00.927461Z"
    }
   },
   "outputs": [],
   "source": [
    "train_candidate_df = pd.read_excel(\"data/compound_gene/sentence_labels.xlsx\")\n",
    "train_candidate_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T14:31:22.072827Z",
     "start_time": "2018-08-23T14:31:22.050161Z"
    }
   },
   "outputs": [],
   "source": [
    "train_candidate_ids = list(map(int, train_candidate_df.candidate_id.values))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T14:31:36.263864Z",
     "start_time": "2018-08-23T14:31:36.158859Z"
    }
   },
   "outputs": [],
   "source": [
    "candidates = session.query(CompoundGene).filter(CompoundGene.id.in_(train_candidate_ids)).limit(100)\n",
    "sv = SentenceNgramViewer(candidates, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T14:31:38.996554Z",
     "start_time": "2018-08-23T14:31:38.958137Z"
    }
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T14:31:41.499178Z",
     "start_time": "2018-08-23T14:31:41.480400Z"
    }
   },
   "outputs": [],
   "source": [
    "c = sv.get_selected()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one of the fundamental part of this project. Below are the label functions that are used to give a candidate a label of 1,0 or -1 which corresponds to correct label, unknown label and incorrection label. The goal here is to develop functions that can label accurately label as many candidates as possible. This idea comes from the [data programming paradigm](https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly), where the goal is to be able to create labels that machine learning algorithms can use for accurate classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:01:39.741855Z",
     "start_time": "2018-08-27T21:01:12.989824Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.disease_gene_lf import DG_LFS\n",
    "from utils.compound_gene_lf import CG_LFS\n",
    "#from utils.gene_gene_lf import *\n",
    "#from utils.compound_disease_lf import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label The Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label each candidate based on the provided labels above. This code runs with realtive ease, but optimization is definitely needed when the number of label functions increases linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:03:31.090485Z",
     "start_time": "2018-08-27T21:03:31.068836Z"
    }
   },
   "outputs": [],
   "source": [
    "from  sqlalchemy.sql.expression import func\n",
    "labeler = LabelAnnotator(lfs=list(CG_LFS[\"CbG_DB\"].values()) + \n",
    "                         list(CG_LFS[\"CbG_TEXT\"].values()) +   \n",
    "                         list(DG_LFS[\"DaG_TEXT\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:51:13.773656Z",
     "start_time": "2018-08-21T17:51:13.759096Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_sentence_df(candidates):\n",
    "    \"\"\" \n",
    "    This function creats a dataframe for all candidates (sentences that contain at least two mentions)\n",
    "    located in our database.\n",
    "    \n",
    "    candidates - a list of candidate objects passed in from sqlalchemy\n",
    "    \"\"\"\n",
    "    rows = list()\n",
    "    for c in tqdm_notebook(candidates):\n",
    "        row = OrderedDict()\n",
    "        row['candidate_id'] = c.id\n",
    "        row['compound'] = c[0].get_span()\n",
    "        row['disease'] = c[1].get_span()\n",
    "        row['drugbank_id'] = c.Compound_cid\n",
    "        row['entrez_gene_id'] = c.Gene_cid\n",
    "        row['sentence'] = c.get_parent().text\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:50:53.200091Z",
     "start_time": "2018-08-21T17:50:51.982522Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT id from candidate\n",
    "WHERE split = 9 and type='compound_gene'\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 50000;\n",
    "'''\n",
    "target_cids = [x[0] for x in session.execute(sql)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:50:55.306081Z",
     "start_time": "2018-08-21T17:50:53.394677Z"
    }
   },
   "outputs": [],
   "source": [
    "candidates = session.query(CompoundGene).filter(CompoundGene.id.in_(target_cids)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:55:29.253437Z",
     "start_time": "2018-08-21T17:51:16.984496Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = make_sentence_df(candidates)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:56:06.172861Z",
     "start_time": "2018-08-21T17:55:56.970387Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data/compound_gene/sentence_labels_train.xlsx')\n",
    "(train_df\n",
    "    .to_excel(writer, sheet_name='sentences', index=False)\n",
    ")\n",
    "if writer.engine == 'xlsxwriter':\n",
    "    for sheet in writer.sheets.values():\n",
    "        sheet.freeze_panes(1, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T14:30:39.694397Z",
     "start_time": "2018-08-23T14:30:39.364522Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT id from candidate\n",
    "WHERE split = 9 and type='compound_gene'\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 1000;\n",
    "'''\n",
    "target_cids = [x[0] for x in session.execute(sql)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:56:37.092197Z",
     "start_time": "2018-08-21T17:56:36.496071Z"
    }
   },
   "outputs": [],
   "source": [
    "candidates = session.query(CompoundGene).filter(CompoundGene.id.in_(target_cids)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:56:43.477290Z",
     "start_time": "2018-08-21T17:56:38.511034Z"
    }
   },
   "outputs": [],
   "source": [
    "train_hand_df = make_sentence_df(candidates)\n",
    "train_hand_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:56:49.460010Z",
     "start_time": "2018-08-21T17:56:49.209280Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data/compound_gene/sentence_labels_train_dev.xlsx')\n",
    "(train_hand_df\n",
    "    .to_excel(writer, sheet_name='sentences', index=False)\n",
    ")\n",
    "if writer.engine == 'xlsxwriter':\n",
    "    for sheet in writer.sheets.values():\n",
    "        sheet.freeze_panes(1, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:57:05.034079Z",
     "start_time": "2018-08-21T17:57:04.768553Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT id from candidate\n",
    "WHERE split = 10 and type='compound_gene'\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 10000;\n",
    "'''\n",
    "gold_cids = [x[0] for x in session.execute(sql)]\n",
    "gold_cids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:57:09.917519Z",
     "start_time": "2018-08-21T17:57:09.543110Z"
    }
   },
   "outputs": [],
   "source": [
    "candidates = session.query(CompoundGene).filter(CompoundGene.id.in_(gold_cids)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:58:01.124706Z",
     "start_time": "2018-08-21T17:57:11.283700Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_df = make_sentence_df(candidates)\n",
    "dev_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:58:02.847974Z",
     "start_time": "2018-08-21T17:58:01.126643Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data/compound_gene/sentence_labels_dev.xlsx')\n",
    "(dev_df\n",
    "    .to_excel(writer, sheet_name='sentences', index=False)\n",
    ")\n",
    "if writer.engine == 'xlsxwriter':\n",
    "    for sheet in writer.sheets.values():\n",
    "        sheet.freeze_panes(1, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickly Relabel Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this block here to re-label candidates that have already been labled from the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:03:49.252090Z",
     "start_time": "2018-08-27T21:03:37.476343Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('data/compound_gene/sentence_labels.xlsx')\n",
    "target_cids = train_df.candidate_id.astype(int).tolist()\n",
    "len(target_cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:23:21.085446Z",
     "start_time": "2018-08-27T21:03:49.253888Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cids = session.query(CompoundGene.id).filter(CompoundGene.id.in_(target_cids))\n",
    "%time L_train = labeler.apply(split=6, cids_query=cids, parallelism=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:23:23.353674Z",
     "start_time": "2018-08-27T21:23:21.087197Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_df = pd.read_excel(\"data/compound_gene/sentence_labels_dev.xlsx\")\n",
    "dev_df = dev_df[dev_df.curated_dsh.notnull()]\n",
    "gold_cids = list(map(int, dev_df.candidate_id.values))\n",
    "#gold_cids = np.loadtxt('data/compound_gene/labeled_dev_candidates.txt').astype(int).tolist()\n",
    "len(gold_cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:23:32.725784Z",
     "start_time": "2018-08-27T21:23:23.355570Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cids = session.query(Candidate.id).filter(Candidate.id.in_(gold_cids))\n",
    "%time L_dev = labeler.apply_existing(cids_query=cids, parallelism=5, clear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:23:32.818823Z",
     "start_time": "2018-08-27T21:23:32.727978Z"
    }
   },
   "outputs": [],
   "source": [
    "train_hand_df = pd.read_excel(\"data/compound_gene/sentence_labels_train_hand.xlsx\")\n",
    "train_hand_cids = train_hand_df[train_hand_df.curated_dsh.notnull()].candidate_id.astype(int).tolist()\n",
    "len(train_hand_cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:23:39.942548Z",
     "start_time": "2018-08-27T21:23:32.820373Z"
    }
   },
   "outputs": [],
   "source": [
    "cids = session.query(Candidate.id).filter(Candidate.id.in_(train_hand_cids))\n",
    "%time L_train_hand_labeled = labeler.apply_existing(cids_query=cids, parallelism=5, clear=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:snorkeling]",
   "language": "python",
   "name": "conda-env-snorkeling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
