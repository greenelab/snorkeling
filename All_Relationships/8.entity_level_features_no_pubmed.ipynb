{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features For Entities Not in Pubmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to calculate features for entities that are not mentioned in the Pubmed database. The features boil down to a pvalue of 1, a prior probability, and how many times a disease/gene is mentioned individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from scipy.stats import fisher_exact\n",
    "import scipy\n",
    "from sqlalchemy import and_\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_curve, auc, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "username = \"danich1\"\n",
    "password = \"snorkel\"\n",
    "dbname = \"pubmeddb\"\n",
    "\n",
    "#Path subject to change for different os\n",
    "database_str = \"postgresql+psycopg2://{}:{}@/{}?host=/var/run/postgresql\".format(username, password, dbname)\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.learning.disc_models.rnn import reRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the Number of Sentences for Each Candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this block of code we are cycling through each disease-gene candidate in the database and counting the number of unique sentences and unique abstracts containing the specific candidate. NOTE: This section will quite a few hours to cycle through the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pair_to_pmids = defaultdict(set)\n",
    "pair_to_sentences = defaultdict(set)\n",
    "offset = 0\n",
    "chunk_size = 1e5\n",
    "\n",
    "while True:\n",
    "    cands = session.query(DiseaseGene).limit(chunk_size).offset(offset).all()\n",
    "    \n",
    "    if not cands:\n",
    "        break\n",
    "        \n",
    "    for candidate in cands:\n",
    "        pair = candidate.Disease_cid, candidate.Gene_cid\n",
    "        pair_to_sentences[pair].add(candidate[0].get_parent().id)\n",
    "        pair_to_pmids[pair].add(candidate[0].get_parent().document_id)\n",
    "\n",
    "    offset+= chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = pd.DataFrame(\n",
    "    map(lambda x: [x[0], x[1], len(pair_to_sentences[x]), len(pair_to_pmids[x])], pair_to_sentences),\n",
    "    columns=[\"disease_id\", \"gene_id\", \"sentence_count\", \"doc_count\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Number of Occurences for Gene and Disease Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"stratified_data/training_set.csv\")\n",
    "dev_df = pd.read_csv(\"stratified_data/dev_set.csv\")\n",
    "test_df = pd.read_csv(\"stratified_data/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.merge(candidate_df, train_df, how='right', on=[\"disease_id\", \"gene_id\"])\n",
    "dev_set = pd.merge(candidate_df, dev_df, how='right', on=[\"disease_id\", \"gene_id\"])\n",
    "test_set = pd.merge(candidate_df, test_df, how='right', on=[\"disease_id\", \"gene_id\"])\n",
    "no_pubmed_df = training_set[training_set[\"sentence_count\"].isnull()].append(dev_set[dev_set[\"sentence_count\"].isnull()])\n",
    "no_pubmed_df = no_pubmed_df.append(test_set[test_set[\"sentence_count\"].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in tqdm.tqdm(no_pubmed_df[[\"disease_id\", \"gene_id\"]].values):\n",
    "    document_disease = candidate_df[candidate_df[\"disease_id\"] == row[0]][\"doc_num\"].sum()\n",
    "    document_gene = candidate_df[candidate_df[\"gene_id\"] == row[1]][\"doc_num\"].sum()\n",
    "    sentence_disease = candidate_df[candidate_df[\"disease_id\"] == row[0]][\"sentence_count\"].sum()\n",
    "    sentence_gene = candidate_df[candidate_df[\"gene_id\"] == row[1]][\"sentence_count\"].sum()\n",
    "    data.append([document_disease, document_gene, sentence_disease, sentence_gene])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write To File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calulating above, the last step is to write to a file and use the dataset in the entity prediction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pubmed_df = pd.concat(\n",
    "    [\n",
    "        no_pubmed_df[[\"disease_id\", \"gene_id\"]],\n",
    "        pd.DataFrame(\n",
    "            data,\n",
    "            index=no_pubmed_df.index,\n",
    "            columns=[\"disease_doc_count\", \"gene_doc_count\", \"disease_sen_count\", \"gene_sen_count\"]\n",
    "        )\n",
    "    ], axis=1\n",
    ")\n",
    "no_pubmed_df[\"p_value\"] = 1\n",
    "no_pubmed_df.to_csv(\"disease_gene_npubmed_summary_stats.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
