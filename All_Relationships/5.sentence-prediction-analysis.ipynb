{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets See How The Disc Models Preformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to analyze the disc models performance and to answer the question does Long Short Term Memory Neural Net (LSTM) outperform SparseLogisticRegression (SLR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST RUN AT THE START OF EVERYTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the database and other helpful functions for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_curve, auc, f1_score\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "username = \"danich1\"\n",
    "password = \"snorkel\"\n",
    "dbname = \"pubmeddb\"\n",
    "\n",
    "#Path subject to change for different os\n",
    "database_str = \"postgresql+psycopg2://{}:{}@/{}?host=/var/run/postgresql\".format(username, password, dbname)\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator, LabelAnnotator, load_marginals\n",
    "from snorkel.learning import SparseLogisticRegression\n",
    "from snorkel.learning.disc_models.rnn import reRNN\n",
    "from snorkel.learning.utils import RandomSearch\n",
    "from snorkel.models import Candidate, FeatureKey, candidate_subclass\n",
    "from snorkel.utils import get_as_dict\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "from tree_structs import corenlp_to_xmltree\n",
    "from treedlib import compile_relation_feature_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edge_type = \"dg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if edge_type == \"dg\":\n",
    "    DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])\n",
    "elif edge_type == \"gg\":\n",
    "    GeneGene = candidate_subclass('GeneGene', ['Gene1', 'Gene2'])\n",
    "elif edge_type == \"cg\":\n",
    "    CompoundGene = candidate_subclass('CompoundGene', ['Compound', 'Gene'])\n",
    "elif edge_type == \"cd\":\n",
    "    CompoundDisease = candidate_subclass('CompoundDisease', ['Compound', 'Disease'])\n",
    "else:\n",
    "    print(\"Please pick a valid edge type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we load the test dataset in conjunction with the previously trained disc models. Each algorithm will output a probability of a candidate being a true candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurizer = FeatureAnnotator()\n",
    "labeler = LabelAnnotator(lfs=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "L_test = labeler.load_matrix(session,split=2)\n",
    "#F_test = featurizer.load_matrix(session, split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_marginals = pd.read_csv(\"Experiment_2/experiment_2.csv\")\n",
    "\n",
    "# Grab the features of the Logistic Regression Model\n",
    "#lr_df = pd.read_csv(\"Experiment 1/LR_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the probabilities calculated above, we can create a [Receiver Operator Curve](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html) (ROC) graph to measure the false positive rate and the true positive rate at each calculated threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = [\"LR_Marginals\", \"RNN_1_Marginals\", \"RNN_10_Marginals\", \"RNN_Full_Marginals\"]\n",
    "#model_colors = [\"darkorange\", \"red\", \"green\", \"magenta\"]\n",
    "#model_labels = [\"LogReg\", \"RNN_1%\", \"RNN_10%\", \"RNN_100%\"]\n",
    "models = [\"RNN_1_Marginals\", \"RNN_10_Marginals\"]\n",
    "model_colors = [\"green\", \"magenta\"]\n",
    "model_labels = [\"RNN_1%\", \"RNN_10%\"]\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "for model_label, marginal_label, color in zip(model_labels, models, model_colors):\n",
    "    fpr, tpr, _= roc_curve(model_marginals[\"True Labels\"], model_marginals[marginal_label])\n",
    "    model_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=color, label=\"{} (area = {:0.2f})\".format(model_label, model_auc))\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Accuracy ROC')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision vs Recall Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code produces a [Precision-Recall](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html) graph, which shows the trade off between [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) at each given probability threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#models = [\"LR_Marginals\", \"RNN_1_Marginals\", \"RNN_10_Marginals\", \"RNN_Full_Marginals\"]\n",
    "#model_colors = [\"darkorange\", \"red\", \"green\", \"magenta\"]\n",
    "#model_labels = [\"LogReg\", \"RNN_1%\", \"RNN_10%\", \"RNN_100%\"]\n",
    "models = [\"RNN_1_Marginals\", \"RNN_10_Marginals\"]\n",
    "model_colors = [\"green\", \"magenta\"]\n",
    "model_labels = [\"RNN_1%\", \"RNN_10%\"]\n",
    "\n",
    "\n",
    "for model_label, marginal_label, color in zip(model_labels, models, model_colors):\n",
    "    precision, recall, _ = precision_recall_curve(model_marginals[\"True Labels\"], model_marginals[marginal_label])\n",
    "    model_precision = average_precision_score(model_marginals[\"True Labels\"], model_marginals[marginal_label])\n",
    "    plt.plot(recall, precision, color=color, label=\"{} curve (area = {:0.2f})\".format(model_label, model_precision))\n",
    "\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('Precision vs Recall')\n",
    "plt.xlim([0, 1.01])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows the amount of true positives, false positives, true negatives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_category = \"tp\"\n",
    "if result_category == \"tp\":\n",
    "    #lr_cond = (model_marginals[\"LR_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == 1)\n",
    "    rnn1_cond = (model_marginals[\"RNN_1_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == 1)\n",
    "    rnn10_cond = (model_marginals[\"RNN_10_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == 1)\n",
    "    #rnn100_cond = (model_marginals[\"RNN_Full_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == 1)\n",
    "elif result_category == \"fp\":\n",
    "    #lr_cond = (model_marginals[\"LR_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == -1)\n",
    "    rnn1_cond = (model_marginals[\"RNN_1_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == -1)\n",
    "    rnn10_cond = (model_marginals[\"RNN_10_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == -1)\n",
    "    #rnn100_cond = (model_marginals[\"RNN_Full_Predictions\"] == 1)&(model_marginals[\"True Labels\"] == -1)\n",
    "elif result_category == \"tn\":\n",
    "    #lr_cond = (model_marginals[\"LR_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == -1)\n",
    "    rnn1_cond = (model_marginals[\"RNN_1_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == -1)\n",
    "    rnn10_cond = (model_marginals[\"RNN_10_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == -1)\n",
    "    #rnn100_cond = (model_marginals[\"RNN_Full_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == -1)\n",
    "elif result_category == \"fn\":\n",
    "    #lr_cond = (model_marginals[\"LR_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == 1)\n",
    "    rnn1_cond = (model_marginals[\"RNN_1_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == 1)\n",
    "    rnn10_cond = (model_marginals[\"RNN_10_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == 1)\n",
    "    #rnn100_cond = (model_marginals[\"RNN_Full_Predictions\"] == -1)&(model_marginals[\"True Labels\"] == 1)\n",
    "else:\n",
    "    print (\"Please re-run cell with correct options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#display_columns = [\"LR_Marginals\", \"RNN_1_Marginals\", \"RNN_10_Marginals\", \"RNN_Full_Marginals\", \"True Labels\"]\n",
    "display_columns = [\"RNN_1_Marginals\", \"RNN_10_Marginals\",\"True Labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_marginals[lr_cond].sort_values(\"LR_Marginals\", ascending=False).head(10)[display_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_index = list(model_marginals[lr_cond].sort_values(\"LR_Marginals\", ascending=False).head(10).index)\n",
    "lr_cands = [L_test.get_candidate(session, i) for i in cand_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Category: {}\".format(result_category)\n",
    "print \n",
    "for cand, cand_ind in zip(lr_cands, cand_index):\n",
    "    text = cand[0].get_parent().text\n",
    "    text = re.sub(cand[0].get_span().replace(\")\", \"\\)\"), \"--[[{}]]D--\".format(cand[0].get_span()), text)\n",
    "    text = re.sub(cand[1].get_span().replace(\")\", \"\\)\"), \"--[[{}]]G--\".format(cand[1].get_span()), text)\n",
    "    print cand_ind\n",
    "    print \"Candidate: \", cand\n",
    "    print\n",
    "    print \"Text: \\\"{}\\\"\".format(text)\n",
    "    print\n",
    "    print \"--------------------------------------------------------------------------------------------\"\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_cand_index = 137865\n",
    "print \"Confidence Level: \", model_marginals[\"LR_Marginals\"][F_cand_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F_cand_index = 137865\n",
    "lr_df.iloc[F_test[F_cand_index, :].nonzero()[1]].sort_values(\"Weight\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand = session.query(Candidate).filter(Candidate.id == L_test.get_candidate(session, 137865).id).one()\n",
    "print cand\n",
    "xmltree = corenlp_to_xmltree(get_as_dict(cand.get_parent()))\n",
    "xmltree.render_tree(highlight=[range(cand[0].get_word_start(), cand[0].get_word_end() + 1), range(cand[1].get_word_start(), cand[1].get_word_end()+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 1% Sub-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_marginals[rnn1_cond].sort_values(\"RNN_1_Marginals\", ascending=False).head(10)[display_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_index = list(model_marginals[rnn1_cond].sort_values(\"RNN_1_Marginals\", ascending=False).head(10).index)\n",
    "lr_cands = [L_test.get_candidate(session, i) for i in cand_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Category: {}\".format(result_category)\n",
    "print \n",
    "for cand in lr_cands:\n",
    "    text = cand[0].get_parent().text\n",
    "    text = re.sub(cand[0].get_span().replace(\")\", \"\\)\"), \"--[[{}]]D--\".format(cand[0].get_span()), text)\n",
    "    text = re.sub(cand[1].get_span().replace(\")\", \"\\)\"), \"--[[{}]]G--\".format(cand[1].get_span()), text)\n",
    "    print \"Candidate: \", cand\n",
    "    print\n",
    "    print \"Text: \\\"{}\\\"\".format(text)\n",
    "    print\n",
    "    print \"--------------------------------------------------------------------------------------------\"\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 10% Sub-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_marginals[rnn10_cond].sort_values(\"RNN_10_Marginals\", ascending=False).head(10)[display_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_index = list(model_marginals[rnn10_cond].sort_values(\"RNN_10_Marginals\", ascending=False).head(10).index)\n",
    "lr_cands = [L_test.get_candidate(session, i) for i in cand_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Category: {}\".format(result_category)\n",
    "print \n",
    "for cand in lr_cands:\n",
    "    text = cand[0].get_parent().text\n",
    "    text = re.sub(cand[0].get_span().replace(\")\", \"\\)\"), \"--[[{}]]D--\".format(cand[0].get_span()), text)\n",
    "    text = re.sub(cand[1].get_span().replace(\")\", \"\\)\"), \"--[[{}]]G--\".format(cand[1].get_span()), text)\n",
    "    print \"Candidate: \", cand\n",
    "    print\n",
    "    print \"Text: \\\"{}\\\"\".format(text)\n",
    "    print\n",
    "    print \"--------------------------------------------------------------------------------------------\"\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert(x, g_start, g_end, d_start, d_end, proba, d_cid, g_cid):\n",
    "    if d_start == x[0] or g_start == x[0]:\n",
    "        pos_str = \"<span title=\\\"{}\\\" style=\\\"background-color: rgba(0,255,0,{})\\\">{}\"\n",
    "        neg_str = \"<span title=\\\"{}\\\" style=\\\"background-color: rgba(255,0,0,{})\\\">{}\"\n",
    "        if proba > 0.5:\n",
    "            return pos_str.format(d_cid, proba, x[1]) if d_start == x[0] else pos_str.format(g_cid, proba, x[1])\n",
    "        else:\n",
    "            return neg_str.format(d_cid, 1-proba, x[1]) if d_start == x[0] else neg_str.format(g_cid, 1-proba, x[1])\n",
    "    elif d_end == x[0] or g_end == x[0]:\n",
    "            return \"{}</span>\".format(x[1])\n",
    "    else:\n",
    "        return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_string = \"\"\n",
    "for cand, proba_index in zip(lr_cands, cand_index):\n",
    "    gene_start = cand[1].char_start\n",
    "    gene_end = cand[1].char_end\n",
    "    disease_start = cand[0].char_start\n",
    "    disease_end = cand[0].char_end\n",
    "    proba = model_marginals[\"RNN_10_Marginals\"].iloc[proba_index]\n",
    "    letters = []\n",
    "    \n",
    "    for x in enumerate(cand[0].get_parent().text):\n",
    "        letters.append(insert(x, gene_start, gene_end, disease_start, disease_end, proba, cand.Disease_cid, cand.Gene_cid))\n",
    "    \n",
    "    html_string += \"<div title=\\\"{}\\\">{}</div><br />\".format(proba, ''.join(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"html/candidate_viewer.html\", 'r') as f:\n",
    "    display(HTML(f.read().format(html_string)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_marginals[rnn100_cond].sort_values(\"RNN_Full_Marginals\", ascending=False).head(10)[display_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_index = list(model_marginals[rnn100_cond].sort_values(\"RNN_Full_Marginals\", ascending=False).head(10).index)\n",
    "lr_cands = [L_test.get_candidate(session, i) for i in cand_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Category: {}\".format(result_category)\n",
    "print \n",
    "for cand in lr_cands:\n",
    "    text = cand[0].get_parent().text\n",
    "    text = re.sub(cand[0].get_span().replace(\")\", \"\\)\"), \"--[[{}]]D--\".format(cand[0].get_span()), text)\n",
    "    text = re.sub(cand[1].get_span().replace(\")\", \"\\)\"), \"--[[{}]]G--\".format(cand[1].get_span()), text)\n",
    "    print \"Candidate: \", cand\n",
    "    print\n",
    "    print \"Text: \\\"{}\\\"\".format(text)\n",
    "    print\n",
    "    print \"--------------------------------------------------------------------------------------------\"\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Results to TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "field_names = [\"Disease ID\", \"Disease Char Start\", \"Disease Char End\", \"Gene ID\", \"Gene Char Start\", \"Gene Char End\", \"Sentence\", \"Prediction\"]\n",
    "with open(\"Experiment_2/LSTM_10_results.tsv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    for i in tqdm.tqdm(model_marginals.index):\n",
    "        cand = L_test.get_candidate(session, i)\n",
    "        row = {\n",
    "                \"Disease ID\": cand.Disease_cid, \"Disease Char Start\":cand[0].char_start, \n",
    "                \"Disease Char End\": cand[0].char_end, \"Gene ID\": cand.Gene_cid, \n",
    "                \"Gene Char Start\":cand[1].char_start, \"Gene Char End\":cand[1].char_end, \n",
    "                \"Sentence\": cand.get_parent().text, \"Prediction\": model_marginals.iloc[i][\"RNN_10_Marginals\"]}\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
