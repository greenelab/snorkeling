{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for True Relationship Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After predicting the co-occurence of candidates on the sentence level, the next step is to predict whether a candidate is a true relationship or just occured by chance. Through out this notebook the main events involved here are calculating summary statistics and obtaining the LSTM marginal probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from scipy.stats import fisher_exact\n",
    "import scipy\n",
    "from sqlalchemy import and_\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "username = \"danich1\"\n",
    "password = \"snorkel\"\n",
    "dbname = \"pubmeddb\"\n",
    "\n",
    "#Path subject to change for different os\n",
    "database_str = \"postgresql+psycopg2://{}:{}@/{}?host=/var/run/postgresql\".format(username, password, dbname)\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "from snorkel.learning.disc_models.rnn import reRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the Number of Sentences for Each Candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this block of code we are cycling through each disease-gene candidate in the database and counting the number of unique sentences and unique abstracts containing the specific candidate. **NOTE**: This section will quite a few hours to cycle through the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pair_to_pmids = defaultdict(set)\n",
    "pair_to_sentences = defaultdict(set)\n",
    "offset = 0\n",
    "chunk_size = 1e5\n",
    "\n",
    "while True:\n",
    "    cands = session.query(DiseaseGene).limit(chunk_size).offset(offset).all()\n",
    "    \n",
    "    if not cands:\n",
    "        break\n",
    "        \n",
    "    for candidate in cands:\n",
    "        pair = candidate.Disease_cid, candidate.Gene_cid\n",
    "        pair_to_sentences[pair].add(candidate[0].get_parent().id)\n",
    "        pair_to_pmids[pair].add(candidate[0].get_parent().document_id)\n",
    "\n",
    "    offset+= chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = pd.DataFrame(\n",
    "    map(lambda x: [x[0], x[1], len(pair_to_sentences[x]), len(pair_to_pmids[x])], pair_to_sentences),\n",
    "    columns=[\"disease_id\", \"gene_id\", \"sentence_count\", \"abstract_count\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Fisher Exact Test on each Co-Occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to perform the fisher exact test for each disease-gene co-occurence. A more detailed explanation [here](https://github.com/greenelab/snorkeling/issues/26)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffprop(obs):\n",
    "    \"\"\"\n",
    "    `obs` must be a 2x2 numpy array.\n",
    "\n",
    "    Returns:\n",
    "    delta\n",
    "        The difference in proportions\n",
    "    ci\n",
    "        The Wald 95% confidence interval for delta\n",
    "    corrected_ci\n",
    "        Yates continuity correction for the 95% confidence interval of delta.\n",
    "    \"\"\"\n",
    "    n1, n2 = obs.sum(axis=1)\n",
    "    prop1 = obs[0,0] / n1.astype(np.float64)\n",
    "    prop2 = obs[1,0] / n2.astype(np.float64)\n",
    "    delta = prop1 - prop2\n",
    "\n",
    "    # Wald 95% confidence interval for delta\n",
    "    se = np.sqrt(prop1*(1 - prop1)/n1 + prop2*(1 - prop2)/n2)\n",
    "    ci = (delta - 1.96*se, delta + 1.96*se)\n",
    "\n",
    "    # Yates continuity correction for confidence interval of delta\n",
    "    correction = 0.5*(1/n1 + 1/n2)\n",
    "    corrected_ci = (ci[0] - correction, ci[1] + correction)\n",
    "\n",
    "    return delta, ci, corrected_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = candidate_df[\"sentence_count\"].sum()\n",
    "odds = []\n",
    "p_val = []\n",
    "expected = []\n",
    "lower_ci = []\n",
    "epsilon = 1e-36\n",
    "\n",
    "for disease, gene in tqdm.tqdm(zip(candidate_df[\"disease_id\"],candidate_df[\"gene_id\"])):\n",
    "    cond_df = candidate_df.query(\"disease_id == @disease & gene_id == @gene\")\n",
    "    a = cond_df[\"sentence_count\"].values[0] + 1\n",
    "                                        \n",
    "    cond_df = candidate_df.query(\"disease_id != @disease & gene_id == @gene\")\n",
    "    b = cond_df[\"sentence_count\"].sum() + 1\n",
    "    \n",
    "    cond_df = candidate_df.query(\"disease_id == @disease & gene_id != @gene\")\n",
    "    c = cond_df[\"sentence_count\"].sum() + 1\n",
    "    \n",
    "    cond_df = candidate_df.query(\"disease_id != @disease & gene_id != @gene\")\n",
    "    d = cond_df[\"sentence_count\"].sum() + 1\n",
    "    \n",
    "    c_table = np.array([[a, b], [c, d]])\n",
    "    \n",
    "    # Gather confidence interval\n",
    "    delta, ci, corrected_ci = diffprop(c_table)\n",
    "    lower_ci.append(ci[0])\n",
    "    \n",
    "    # Gather corrected odds ratio and p_values\n",
    "    odds_ratio, p_value = fisher_exact(c_table, alternative='greater')\n",
    "    odds.append(odds_ratio)\n",
    "    p_val.append(p_value + epsilon)\n",
    "    \n",
    "    total_disease = candidate_df[candidate_df[\"disease_id\"] == disease][\"sentence_count\"].sum()\n",
    "    total_gene = candidate_df[candidate_df[\"gene_id\"] == gene][\"sentence_count\"].sum()\n",
    "    expected.append((total_gene * total_disease)/float(total))\n",
    "\n",
    "candidate_df[\"nlog10_p_value\"] = (-1 * np.log10(p_val))\n",
    "candidate_df[\"co_odds_ratio\"] = odds\n",
    "candidate_df[\"co_expected_sen_count\"] = expected\n",
    "candidate_df[\"delta_lower_ci\"] = lower_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidate_df.sort_values(\"nlog10_p_value\", ascending=False).head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Sentence Marginal Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we incorporate the marginal probabilites that are calculated from the bi-directional LSTM used in the [previous notebook](4.sentence-level-prediction.ipynb). For each sentence we grouped them by their disease-gene mention and report their marginal probabilites in different quantiles (0, 0.2, 0.4, 0.6, 0.8). Lastly we took the average of each sentence marginal to generate the \"avg_marginal\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals_df = pd.read_csv(\"vanilla_lstm/lstm_disease_gene_holdout/full_data/lstm_train_full_marginals.csv\")\n",
    "dev_marginals_df = pd.read_csv(\"vanilla_lstm/lstm_disease_gene_holdout/full_data/lstm_dev_full_marginals.csv\")\n",
    "test_marginals_df = pd.read_csv(\"vanilla_lstm/lstm_disease_gene_holdout/full_data/lstm_test_full_marginals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_df = pd.read_csv(\"stratified_data/lstm_disease_gene_holdout/train_candidates_sentences.csv\")\n",
    "dev_sentences_df = pd.read_csv(\"stratified_data/lstm_disease_gene_holdout/dev_candidates_sentences.csv\")\n",
    "test_sentences_df = pd.read_csv(\"stratified_data/lstm_disease_gene_holdout/test_candidates_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sentences_df[\"marginals\"] = train_marginals_df[\"RNN_marginals\"].values\n",
    "dev_sentences_df[\"marginals\"] = dev_marginals_df[\"RNN_marginals\"].values\n",
    "test_sentences_df[\"marginals\"] = test_marginals_df[\"RNN_marginals\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_marginals = (\n",
    "    train_sentences_df[[\"disease_id\", \"gene_id\", \"marginals\"]]\n",
    "    .append(dev_sentences_df[[\"disease_id\", \"gene_id\", \"marginals\"]])\n",
    "    .append(test_sentences_df[[\"disease_id\", \"gene_id\", \"marginals\"]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_map = pd.read_csv(\"dg_map.csv\").rename(\n",
    "    columns={\"disease_ontology\":\"disease_id\"},index=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quantile_list = [0,0.2,0.4,0.6,0.8]\n",
    "quantile_data = []\n",
    "avg_marginals = []\n",
    "group = candidate_marginals.groupby([\"disease_id\", \"gene_id\"])\n",
    "\n",
    "for i, cand in tqdm.tqdm(candidate_df[[\"disease_id\", \"gene_id\"]].iterrows()):\n",
    "    dg_series = group.get_group((cand[\"disease_id\"], cand[\"gene_id\"]))\n",
    "    avg_marginals.append(dg_series[\"marginals\"].mean())\n",
    "    quantile_data.append(list(map(lambda x: dg_series[\"marginals\"].quantile(x), quantile_list)))\n",
    "\n",
    "# Save the evidence into a dataframe\n",
    "candidate_df = pd.concat(\n",
    "    [\n",
    "        candidate_df,\n",
    "        pd.DataFrame(\n",
    "            quantile_data,\n",
    "            index=candidate_df.index,\n",
    "            columns=list(map(lambda x: 'lstm_marginal_{:.0f}_quantile'.format(x*100), quantile_list))\n",
    "        )\n",
    "    ], axis=1\n",
    ")\n",
    "candidate_df = pd.merge(candidate_df, \n",
    "                        dg_map[[\"disease_id\", \"disease_name\", \"gene_id\", \"gene_name\"]],\n",
    "                        on=[\"disease_id\", \"gene_id\"], how=\"inner\"\n",
    "                       ).drop_duplicates([\"disease_id\", \"gene_id\"])\n",
    "candidate_df[\"lstm_avg_marginal\"] = avg_marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df.to_csv(\"data/disease_gene_summary_stats.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
