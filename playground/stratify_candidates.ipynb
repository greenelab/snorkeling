{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Organize the Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [previous notebook](1.data-loader.ipynb) we aim to stratify the candidates into the appropiate categories (training, development, test). This part is easy because the only intensive operation is to update rows in a database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T14:53:46.440285Z",
     "start_time": "2018-08-27T14:53:46.127787Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#Imports\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T14:53:46.603633Z",
     "start_time": "2018-08-27T14:53:46.441782Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "username = \"danich1\"\n",
    "password = \"snorkel\"\n",
    "dbname = \"pubmeddb\"\n",
    "\n",
    "#Path subject to change for different os\n",
    "database_str = \"postgresql+psycopg2://{}:{}@/{}?host=/var/run/postgresql\".format(username, password, dbname)\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T14:53:46.616450Z",
     "start_time": "2018-08-27T14:53:46.605049Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.models import  candidate_subclass, Candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the Candidate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:12:58.350723Z",
     "start_time": "2018-08-27T15:12:42.787249Z"
    }
   },
   "outputs": [],
   "source": [
    "#from utils.datafiles.disease_gene_datafiles import dag_map_df as map_df\n",
    "from utils.datafiles.compound_gene_datafiles import cbg_map_df as map_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below changes the split column of the candidate table. This column is what separates each sentence candidate into the corresponding categories (training, dev, test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:55:48.933797Z",
     "start_time": "2018-07-31T15:55:48.804415Z"
    }
   },
   "outputs": [],
   "source": [
    "def partitioner(df):\n",
    "    \"\"\"\n",
    "    This function creates a parition rank for the current dataset.\n",
    "    This algorithm assigns a rank [0-1) for each datapoint inside each group (outlined below):\n",
    "        1,1 -in hetionet and has sentences\n",
    "        1,0 - in hetionet and doesn't have sentences\n",
    "        0,1 - not in hetionet and does have sentences\n",
    "        0,0, - not in hetionet and doesn't have sentences\n",
    "        \n",
    "    This ranking will be used in the get split function to assign each datapoint \n",
    "    into its corresponding category (train, dev, test)\n",
    "    \"\"\"\n",
    "    partition_rank = pd.np.linspace(0, 1, num=len(df), endpoint=False)\n",
    "    pd.np.random.shuffle(partition_rank)\n",
    "    df['partition_rank'] = partition_rank\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.np.random.seed(100)\n",
    "map_df = dg_map_df.groupby(['hetionet', 'has_sentence']).apply(partitioner)\n",
    "map_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:55:49.049038Z",
     "start_time": "2018-07-31T15:55:48.935373Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_split(partition_rank, training=0.7, dev=0.2, test=0.1):\n",
    "    \"\"\"\n",
    "    This function partitions the data into training, dev, and test sets\n",
    "    The partitioning algorithm is as follows:\n",
    "        1. anything less than 0.7 goes into training and receives an appropiate label\n",
    "        2. If not less than 0.7 subtract 0.7 and see if the rank is less than 0.2 if not assign to dev\n",
    "        3. Lastly if the rank is greater than 0.9 (0.7+0.2) assign it to test set.\n",
    "        \n",
    "    return label that corresponds to appropiate dataset cateogories\n",
    "    \"\"\"\n",
    "    if partition_rank < training:\n",
    "        return 6\n",
    "    partition_rank -= training\n",
    "    if partition_rank < dev:\n",
    "        return 7\n",
    "    partition_rank -= dev\n",
    "    assert partition_rank <= test\n",
    "    return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df['split'] = dg_map_df.partition_rank.map(get_split)\n",
    "map_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:55:50.325678Z",
     "start_time": "2018-07-31T15:55:50.305082Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_df.sources.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df.to_csv(\"data/compound_gene/compound_binds_gene/compound_gene_pairs_binds.csv\", index=False, float_format='%.5g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-categorize The Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:11:06.794185Z",
     "start_time": "2018-07-31T16:10:59.485355Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT id, \"Compound_cid\" AS drugbank_id, \"Gene_cid\" AS entrez_gene_id \n",
    "FROM compound_gene\n",
    "'''\n",
    "candidate_df = (\n",
    "    pd.read_sql(sql, database_str)\n",
    "    .astype(dtype={'entrez_gene_id': int})\n",
    "    .merge(map_df, how='left')\n",
    "    .assign(type='compound_gene')\n",
    "    [[\"id\", \"type\", \"split\"]]\n",
    "    .dropna(axis=0)\n",
    ")\n",
    "candidate_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:11:33.880861Z",
     "start_time": "2018-07-31T16:11:33.846130Z"
    }
   },
   "outputs": [],
   "source": [
    "candidate_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:11:35.510301Z",
     "start_time": "2018-07-31T16:11:35.494022Z"
    }
   },
   "outputs": [],
   "source": [
    "candidate_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Candidate table in database with splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T19:06:44.321960Z",
     "start_time": "2018-07-31T16:11:39.698687Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "session.bulk_update_mappings(\n",
    "    Candidate,\n",
    "    candidate_df.to_dict(orient='records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T19:24:40.476450Z",
     "start_time": "2018-07-31T19:24:31.082087Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.testing import assert_frame_equal\n",
    "sql = '''\n",
    "SELECT * FROM candidate\n",
    "WHERE type = 'compound_gene';\n",
    "'''\n",
    "db_df = pd.read_sql(sql, database_str).sort_values('id')\n",
    "compare_df = db_df.merge(candidate_df, on=['id', 'type'])\n",
    "(compare_df.split_x == compare_df.split_y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T19:24:45.588348Z",
     "start_time": "2018-07-31T19:24:45.552609Z"
    }
   },
   "outputs": [],
   "source": [
    "db_df.split.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorkeling]",
   "language": "python",
   "name": "conda-env-snorkeling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
