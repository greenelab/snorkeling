{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUST RUN AT THE START OF EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_curve, auc\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.annotations import FeatureAnnotator\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "from snorkel.learning import NaiveBayes, RandomSearch, ListParameter, RangeParameter\n",
    "from snorkel.learning import SparseLogisticRegression\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.models import Candidate, FeatureKey, candidate_subclass\n",
    "from snorkel.utils import get_as_dict\n",
    "from tree_structs import corenlp_to_xmltree\n",
    "from treedlib import compile_relation_feature_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database_str = \"sqlite:///\" + os.environ['WORKINGPATH'] + \"/Database/epilepsy.db\"\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, this code will automatically load our labels that were generated in the previous file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeler = LabelAnnotator(f=None)\n",
    "\n",
    "L_train = labeler.load_matrix(session,split=0)\n",
    "L_dev = labeler.load_matrix(session,split=1)\n",
    "L_test = labeler.load_matrix(session,split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Total Data Shape:\"\n",
    "print L_train.shape\n",
    "print L_dev.shape\n",
    "print L_test.shape\n",
    "print\n",
    "\n",
    "print \"The number of positive candiadtes (in KB) for each division:\"\n",
    "print L_train[(L_train[:,0] > 0)].shape\n",
    "print L_dev[(L_dev[:,0] > 0)].shape\n",
    "print L_test[L_test[:,0] > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurizer = FeatureAnnotator()\n",
    "\n",
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev = featurizer.load_matrix(session, split=1)\n",
    "F_test = featurizer.load_matrix(session, split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the machine learning models below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are still in development stage below are just two generative models designed to model p(Labels,y). Until we can discuss more about the classifiers we want to use, feel free to run the below code and see some cool output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KB = L_train[:,0]\n",
    "KB_CONTEXT = L_train\n",
    "train_marginals = []\n",
    "gen_model = NaiveBayes()\n",
    "\n",
    "for models in [KB,KB_CONTEXT]:\n",
    "    gen_model.train(models)\n",
    "    train_marginals.append(gen_model.marginals(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(train_marginals[0],bins=20)\n",
    "plt.title(\"KB\")\n",
    "plt.show()\n",
    "plt.hist(train_marginals[1],bins=20)\n",
    "plt.title(\"KB + Context\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disc Model With Hyper-Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Searching over learning rate\n",
    "rate_param = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l1_param  = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param  = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1701)\n",
    "test_marginals = []\n",
    "disc_models = []\n",
    "weights = []\n",
    "\n",
    "for i,L_classes in enumerate([KB,KB_CONTEXT]):\n",
    "    print i\n",
    "    disc_model = SparseLogisticRegression()\n",
    "    searcher = RandomSearch(session, disc_model, F_train, train_marginals[i], [rate_param, l1_param, l2_param], n=20)\n",
    "    searcher.fit(F_dev, L_dev, n_epochs=50, rebalance=0.5, print_freq=25)\n",
    "    disc_models.append(disc_model)\n",
    "    w = disc_model.save_dict['w']\n",
    "    f = w.read_value()\n",
    "    values = f.eval(session = disc_model.session)\n",
    "    weights.append(values)\n",
    "    test_marginals.append(disc_model.marginals(F_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Statistics After Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = session.query(FeatureKey).all()\n",
    "feat_data = []\n",
    "for feat, w0, w1 in zip(features,weights[0],weights[1]):\n",
    "    feat_data.append([feat.name, w0[0], w1[0]])\n",
    "feat_frame = pd.DataFrame(feat_data, columns= [\"Feature\", \"Model_KB\", \"Model_KB_CONTEXT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_marginals[0].shape\n",
    "cand_probs = []\n",
    "for candidate_id in L_test.candidate_index:\n",
    "    cand = session.query(Candidate).filter(Candidate.id == candidate_id).one()\n",
    "    index = L_test.candidate_index[candidate_id]\n",
    "    data = [cand[0].get_span(), cand[1].get_span(),test_marginals[0][index], test_marginals[1][index]]\n",
    "    data.append(cand.get_parent().text)\n",
    "    data.append(L_test[:,0][index].toarray()[0][0])\n",
    "    cand_probs.append(data)\n",
    "cand_stats = pd.DataFrame(cand_probs, columns = [\"Disease\", \"Gene\", \"Model_KB\", \"Model_KB_CONTEXT\",\"Sentence\",\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_frame.sort_values(\"Model_KB\", ascending=False, inplace=True)\n",
    "feat_frame.to_csv(\"features.tsv\", sep=\"\\t\", index=False, float_format='%.4g')\n",
    "cand_stats.sort_values(['Model_KB', 'Model_KB_CONTEXT'], ascending=False, inplace=True)\n",
    "cand_stats.to_csv(\"model_predictions.tsv\",sep=\"\\t\", index=False, float_format='%.4g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the feature weight distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(feat_frame[\"Model_KB\"], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the class probability correlation between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"muted\")\n",
    "\n",
    "# Blue is positive labels\n",
    "sns.jointplot(data=cand_stats[cand_stats[\"Label\"]==1], x=\"Model_KB\", y=\"Model_KB_CONTEXT\", kind=\"hex\", color=colors[0])\n",
    "\n",
    "#Green is the negative labels\n",
    "sns.jointplot(data=cand_stats[cand_stats[\"Label\"]==-1], x=\"Model_KB\", y=\"Model_KB_CONTEXT\", kind=\"hex\", color=colors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Curve Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_models = []\n",
    "roc_models = []\n",
    "for marginal in test_marginals:    \n",
    "    fpr, tpr, thresholds = roc_curve(list(L_test[:,0]),marginal,pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(L_test[:,0].todense(),marginal,pos_label=1)\n",
    "    avg_precision = average_precision_score(L_test[:,0].todense(), marginal)\n",
    "    \n",
    "    roc_models.append(tuple([fpr,tpr,roc_auc]))\n",
    "    pr_models.append(tuple([recall,precision,avg_precision]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_names = [\"KB\", \"KB+Context\"]\n",
    "color_vals = [\"darkorange\", \"cyan\", \"red\"]\n",
    "for i,model in enumerate(pr_models):\n",
    "    plt.plot(model[0],model[1], color=color_vals[i],\n",
    "         lw=2, label='%s (area = %0.2f)' % (model_names[i],model[2]))\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_names = [\"KB\", \"KB+Context\"]\n",
    "color_vals = [\"darkorange\", \"cyan\", \"red\"]\n",
    "for i,model in enumerate(roc_models):\n",
    "    plt.plot(model[0],model[1], color=color_vals[i],\n",
    "         lw=2, label='%s (area = %0.2f)' % (model_names[i],model[2]))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cand = session.query(Candidate).filter(Candidate.id == 19885).one()\n",
    "print cand\n",
    "xmltree = corenlp_to_xmltree(get_as_dict(cand.get_parent()))\n",
    "xmltree.render_tree(highlight=[range(cand[0].get_word_start(), cand[0].get_word_end() + 1), range(cand[1].get_word_start(), cand[1].get_word_end()+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_tdl_feats = compile_relation_feature_generator()\n",
    "sids = [range(a.get_word_start(), a.get_word_end() + 1) for a in cand.get_contexts()]\n",
    "tags = list(get_tdl_feats(xmltree.root, sids[0], sids[1]))\n",
    "print tags"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
