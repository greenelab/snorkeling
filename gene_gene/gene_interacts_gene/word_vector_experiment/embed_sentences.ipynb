{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Word Vectors For Gene Interacts Gene Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to embed gene interacts gene (GiG) sentences. After word vectors have been trained, we embed sentences using the following steps:\n",
    "\n",
    "1. Load the total vocab generated from trained word vectors.\n",
    "2. Cycle through each sentence\n",
    "3. For each word in the sentence determine if word is in vocab\n",
    "4. if yes assign index of no assign index for unknown token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:12:11.288434Z",
     "start_time": "2019-10-25T15:12:04.873904Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../../../modules'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from utils.notebook_utils.dataframe_helper import load_candidate_dataframes, generate_embedded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:12:15.565756Z",
     "start_time": "2019-10-25T15:12:14.688059Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "username = \"danich1\"\n",
    "password = \"snorkel\"\n",
    "dbname = \"pubmeddb\"\n",
    "\n",
    "#Path subject to change for different os\n",
    "database_str = \"postgresql+psycopg2://{}:{}@/{}?host=/var/run/postgresql\".format(username, password, dbname)\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:12:18.189272Z",
     "start_time": "2019-10-25T15:12:15.567626Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.pytorch.rnn.rnn_base import mark_sentence\n",
    "from snorkel.learning.pytorch.rnn.utils import candidate_to_tokens\n",
    "from snorkel.models import Candidate, candidate_subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:12:18.235651Z",
     "start_time": "2019-10-25T15:12:18.194492Z"
    }
   },
   "outputs": [],
   "source": [
    "GeneGene = candidate_subclass('GeneGene', ['Gene1', 'Gene2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Interacts Gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section loads the dataframe that contains all gene interacts gene candidate sentences and their respective dataset assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:13:31.766030Z",
     "start_time": "2019-10-25T15:12:18.310173Z"
    }
   },
   "outputs": [],
   "source": [
    "total_candidates_df = (\n",
    "    pd.read_table(\"../dataset_statistics/results/all_gig_candidates.tsv.xz\")\n",
    "    .query(\"sen_length < 300\")\n",
    ")\n",
    "total_candidates_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed all Gene Interacts Gene Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section embeds all candidate sentences. For each sentence, we place tags around each mention, tokenized the sentence and then matched each token to their corresponding word index. Any words missing from our vocab receive a index of 1. Lastly, the embedded sentences are exported as a sparse dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:13:32.305954Z",
     "start_time": "2019-10-25T15:13:31.767955Z"
    }
   },
   "outputs": [],
   "source": [
    "word_dict_df = pd.read_table(\"results/gene_interacts_gene_word_dict.tsv\")\n",
    "word_dict = {word[0]:word[1] for word in word_dict_df.values.tolist()}\n",
    "fixed_word_dict = {word:word_dict[word] + 2 for word in word_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:12:19.672Z"
    }
   },
   "outputs": [],
   "source": [
    "limit = 1000000\n",
    "total_candidate_count = total_candidates_df.shape[0]\n",
    "\n",
    "for offset in list(range(0, total_candidate_count, limit)):\n",
    "    candidates = (\n",
    "        session\n",
    "        .query(GeneGene)\n",
    "        .filter(\n",
    "            GeneGene.id.in_(\n",
    "                total_candidates_df\n",
    "                .candidate_id\n",
    "                .astype(int)\n",
    "                .tolist()\n",
    "            )\n",
    "        )\n",
    "        .offset(offset)\n",
    "        .limit(limit)\n",
    "        .all()\n",
    "    )\n",
    "    \n",
    "    max_length = total_candidates_df.sen_length.max()\n",
    "\n",
    "    # if first iteration create the file\n",
    "    if offset == 0:\n",
    "        (\n",
    "            generate_embedded_df(candidates, fixed_word_dict, max_length=max_length)\n",
    "            .to_csv(\n",
    "                \"results/all_embedded_gg_sentences_fixed.tsv\",\n",
    "                index=False, \n",
    "                sep=\"\\t\", \n",
    "                mode=\"w\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # else append don't overwrite\n",
    "    else:\n",
    "        (\n",
    "            generate_embedded_df(candidates, fixed_word_dict, max_length=max_length)\n",
    "            .to_csv(\n",
    "                \"results/all_embedded_gg_sentences_fixed.tsv\",\n",
    "                index=False, \n",
    "                sep=\"\\t\", \n",
    "                mode=\"a\",\n",
    "                header=False\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:12:21.739Z"
    }
   },
   "outputs": [],
   "source": [
    "os.system(\"cd results; xz all_embedded_gg_sentences_fixed.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorkeling]",
   "language": "python",
   "name": "conda-env-snorkeling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
