{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Word Vectors For Compound Binds Gene Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to generate word vectors for compound binds gene (CbG) sentences. Using facebooks's fasttext, we trained word vectors using all sentences that contain a disease and gene mention. The model was trained using the following specifications:\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| Size | 300 |\n",
    "| alpha | 0.005 | \n",
    "| window | 2 |\n",
    "| epochs | 50 |\n",
    "| seed | 100 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T14:38:52.761376Z",
     "start_time": "2019-06-07T14:38:51.995480Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "sys.path.append(os.path.abspath('../../../modules'))\n",
    "\n",
    "from utils.notebook_utils.dataframe_helper import load_candidate_dataframes, generate_embedded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T14:38:52.978595Z",
     "start_time": "2019-06-07T14:38:52.763282Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "username = \"danich1\"\n",
    "password = \"snorkel\"\n",
    "dbname = \"pubmeddb\"\n",
    "\n",
    "#Path subject to change for different os\n",
    "database_str = \"postgresql+psycopg2://{}:{}@/{}?host=/var/run/postgresql\".format(username, password, dbname)\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T14:38:53.355748Z",
     "start_time": "2019-06-07T14:38:52.980097Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.pytorch.rnn.rnn_base import mark_sentence\n",
    "from snorkel.learning.pytorch.rnn.utils import candidate_to_tokens\n",
    "from snorkel.models import Candidate, candidate_subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T14:38:53.379966Z",
     "start_time": "2019-06-07T14:38:53.357488Z"
    }
   },
   "outputs": [],
   "source": [
    "CompoundGene = candidate_subclass('CompoundGene', ['Compound', 'Gene'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compound Binds Gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section loads the dataframe that contains all compound binds gene candidate sentences and their respective dataset assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T14:39:08.530684Z",
     "start_time": "2019-06-07T14:38:53.381499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entrez_gene_id</th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>drugbank_id</th>\n",
       "      <th>name</th>\n",
       "      <th>sources</th>\n",
       "      <th>hetionet</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>has_sentence</th>\n",
       "      <th>partition_rank</th>\n",
       "      <th>split</th>\n",
       "      <th>compound_mention_count</th>\n",
       "      <th>disease_mention_count</th>\n",
       "      <th>gene_mention_count</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sen_length</th>\n",
       "      <th>candidate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>DB00117</td>\n",
       "      <td>L-Histidine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37753</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>94389805</td>\n",
       "      <td>Thus, as the assessment of protein glycosylati...</td>\n",
       "      <td>114</td>\n",
       "      <td>33517095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>DB00143</td>\n",
       "      <td>Glutathione</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30352</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83523801</td>\n",
       "      <td>Similar observations were made in T98 glioma c...</td>\n",
       "      <td>34</td>\n",
       "      <td>28913100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entrez_gene_id gene_symbol drugbank_id         name sources  hetionet  \\\n",
       "0               1        A1BG     DB00117  L-Histidine     NaN         0   \n",
       "1               1        A1BG     DB00143  Glutathione     NaN         0   \n",
       "\n",
       "   n_sentences  has_sentence  partition_rank  split  compound_mention_count  \\\n",
       "0            1             1         0.37753      6                     1.0   \n",
       "1            1             1         0.30352      6                     1.0   \n",
       "\n",
       "   disease_mention_count  gene_mention_count  sentence_id  \\\n",
       "0                    0.0                10.0     94389805   \n",
       "1                    1.0                 2.0     83523801   \n",
       "\n",
       "                                                text  sen_length  candidate_id  \n",
       "0  Thus, as the assessment of protein glycosylati...         114      33517095  \n",
       "1  Similar observations were made in T98 glioma c...          34      28913100  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = 300\n",
    "total_candidates_df = (\n",
    "    pd.read_table(\"../dataset_statistics/data/all_cbg_candidates.tsv.xz\")\n",
    "    .query(\"sen_length < @cutoff\")\n",
    ")\n",
    "total_candidates_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section trains the word vectors using the specifications described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T19:04:09.080284Z",
     "start_time": "2019-06-01T19:02:40.483737Z"
    }
   },
   "outputs": [],
   "source": [
    "words_to_embed = []\n",
    "candidates = (\n",
    "    session\n",
    "    .query(CompoundGene)\n",
    "    .filter(\n",
    "        CompoundGene.id.in_(\n",
    "            total_candidates_df\n",
    "            .candidate_id\n",
    "            .astype(int)\n",
    "            .tolist()\n",
    "        )\n",
    "    )\n",
    "    .all()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T20:49:24.384399Z",
     "start_time": "2019-06-01T19:04:09.081924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7953c5585974217bb3650e45e6a3676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2417701), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cand in tqdm_notebook(candidates):\n",
    "    args = [\n",
    "                (cand[0].get_word_start(), cand[0].get_word_end(), 1),\n",
    "                (cand[1].get_word_start(), cand[1].get_word_end(), 2)\n",
    "    ]\n",
    "    words_to_embed.append(mark_sentence(candidate_to_tokens(cand), args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T02:45:47.516102Z",
     "start_time": "2019-06-01T20:49:24.390269Z"
    }
   },
   "outputs": [],
   "source": [
    "model = FastText(\n",
    "    words_to_embed, \n",
    "    window=2, \n",
    "    negative=10, \n",
    "    iter=50, \n",
    "    sg=1, \n",
    "    workers=4, \n",
    "    alpha=0.005, \n",
    "    size=300, \n",
    "    seed=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T02:46:22.389409Z",
     "start_time": "2019-06-02T02:45:47.517767Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    model\n",
    "    .wv\n",
    "    .save_word2vec_format(\n",
    "        \"results/compound_gene_word_vectors.bin\", \n",
    "        fvocab=\"results/compound_gene_word_vocab.txt\", \n",
    "        binary=False\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T02:46:24.194708Z",
     "start_time": "2019-06-02T02:46:22.390937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danich1/anaconda2/envs/snorkeling/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('diabete', 0.9036514759063721),\n",
       " ('prediabetes', 0.8539975881576538),\n",
       " ('mellitus', 0.818751335144043),\n",
       " ('diabetes.genetic', 0.7914907932281494),\n",
       " ('diabetes-prone', 0.7878351807594299),\n",
       " ('pre-diabetes', 0.786160945892334),\n",
       " ('type-1-diabetes', 0.7588273286819458),\n",
       " ('diabetics', 0.7325868606567383),\n",
       " ('diabetic', 0.7215651869773865),\n",
       " ('diabetes-reduced', 0.7057150602340698)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"diabetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T02:46:25.072058Z",
     "start_time": "2019-06-02T02:46:24.204241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>serum</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hormone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  index\n",
       "0    serum      0\n",
       "1  hormone      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {val[1]:val[0] for val in list(enumerate(model.wv.vocab.keys()))}\n",
    "word_dict_df = (\n",
    "    pd\n",
    "    .DataFrame\n",
    "    .from_dict(word_dict, orient=\"index\")\n",
    "    .reset_index()\n",
    "    .rename({\"index\":\"word\", 0:\"index\"}, axis=1)\n",
    ")\n",
    "word_dict_df.to_csv(\"results/compound_gene_word_dict.tsv\", sep=\"\\t\", index=False)\n",
    "word_dict_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed all Compound Binds Gene Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Must run this section separately because the kernel cannot handle both training the word vectors and then embedding each CbG sentence.\n",
    "\n",
    "This section embesd all candidate sentences. For each sentence, we place tags around each mention, tokenized the sentence and then matched each token to their corresponding word index. Any words missing from our vocab receive a index of 1. Lastly, the embedded sentences are exported as a sparse dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T14:39:08.828017Z",
     "start_time": "2019-06-07T14:39:08.532364Z"
    }
   },
   "outputs": [],
   "source": [
    "word_dict_df = pd.read_table(\"results/compound_gene_word_dict.tsv\")\n",
    "word_dict = {word[0]:word[1] for word in word_dict_df.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-07T14:39:39.039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5355dc85ec4a03ac2b966b3485dcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "limit = 500000 #1000000\n",
    "total_candidate_count = total_candidates_df.shape[0]\n",
    "\n",
    "for offset in list(range(0, total_candidate_count, limit)):\n",
    "    candidates = (\n",
    "        session\n",
    "        .query(CompoundGene)\n",
    "        .filter(\n",
    "            CompoundGene.id.in_(\n",
    "                total_candidates_df\n",
    "                .candidate_id\n",
    "                .astype(int)\n",
    "                .tolist()\n",
    "            )\n",
    "        )\n",
    "        .offset(offset)\n",
    "        .limit(limit)\n",
    "        .all()\n",
    "    )\n",
    "    \n",
    "    max_length = total_candidates_df.sen_length.max()\n",
    "    \n",
    "    # if first iteration create the file\n",
    "    if offset == 0:\n",
    "        (\n",
    "            generate_embedded_df(candidates, word_dict, max_length=max_length)\n",
    "            .to_csv(\n",
    "                \"results/all_embedded_cg_sentences.tsv\",\n",
    "                index=False, \n",
    "                sep=\"\\t\",\n",
    "                mode=\"w\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # else append don't overwrite\n",
    "    else:\n",
    "        (\n",
    "            generate_embedded_df(candidates, word_dict, max_length=max_length)\n",
    "            .to_csv(\n",
    "                \"results/all_embedded_cg_sentences.tsv\",\n",
    "                index=False, \n",
    "                sep=\"\\t\", \n",
    "                mode=\"a\",\n",
    "                header=False\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"cd results; xz all_embedded_cg_sentences.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorkeling]",
   "language": "python",
   "name": "conda-env-snorkeling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
