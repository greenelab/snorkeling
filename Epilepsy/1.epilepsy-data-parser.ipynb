{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUST RUN AT THE START OF EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#Imports\n",
    "import os\n",
    "import random\n",
    "\n",
    "from epilepsy_utils import XMLMultiDocPreprocessor\n",
    "from epilepsy_utils import Tagger\n",
    "import pandas as pd\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "from snorkel.models import Document, Sentence, candidate_subclass\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "database_str = \"sqlite:///\" + os.environ['WORKINGPATH'] + \"/Database/epilepsy.db\"\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the Pubmed Abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is designed to read and parse data gathered from pubtator. Pubtator outputs their annotated text in xml format, so that is the standard file format we are going to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_path = os.environ['WORKINGPATH']\n",
    "xml_parser = XMLMultiDocPreprocessor(\n",
    "    path= working_path + '/Database/epilepsy_data.xml',\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "working_path = os.environ['WORKINGPATH']\n",
    "dg_tagger = Tagger(working_path + \"/Database/epilepsy_tags_shelve\")\n",
    "corpus_parser = CorpusParser(fn=dg_tagger.tag)\n",
    "%time corpus_parser.apply(list(xml_parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Documents: \", session.query(Document).count()\n",
    "print \"Sentences: \", session.query(Sentence).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get each candidate relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code below is designed to gather and tag each sentence found. **Note**: This does include the title of each abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_df = pd.read_csv(\"epilepsy-genes.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is a quick divide the documents without checking if they have gold standard or not\n",
    "\n",
    "random.seed(100)\n",
    "#Grab the sentences!!!\n",
    "train_sents,dev_sents,test_sents = set(),set(),set()\n",
    "docs = session.query(Document).all()\n",
    "for doc in tqdm.tqdm(docs):\n",
    "    for s in doc.sentences:\n",
    "        in_dev = random.random() * 100 < 50\n",
    "        if 'Gene' in s.entity_types:\n",
    "            if \";\" in s.entity_cids[s.entity_types.index('Gene')]:\n",
    "                cand = s.entity_cids[s.entity_types.index('Gene')].split(\";\")[0]\n",
    "                cand = int(cand)\n",
    "            else:\n",
    "                cand = int(s.entity_cids[s.entity_types.index('Gene')])\n",
    "            if cand in set(gene_df[gene_df[\"testing\"] == 1][\"entrez_gene_id\"]):\n",
    "                test_sents.add(s)\n",
    "            else:\n",
    "                if in_dev:\n",
    "                    dev_sents.add(s)\n",
    "                else:\n",
    "                    train_sents.add(s)\n",
    "        else:\n",
    "            if in_dev:\n",
    "                dev_sents.add(s)\n",
    "            else:\n",
    "                train_sents.add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(train_sents)\n",
    "print len(dev_sents)\n",
    "print len(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This specifies that I want candidates that have a disease and gene mentioned in a given sentence\n",
    "DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ce = PretaggedCandidateExtractor(DiseaseGene, ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the candidates from my custom tagger and then print number of candidates found\n",
    "for k,sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    ce.apply(sents,split=k)\n",
    "    print \"Number of Candidates: \", session.query(DiseaseGene).filter(DiseaseGene.split == k).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the Potential Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one cool thing about jupyter is that you can use this tool to look at candidates. Check it out after everything above has finished running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = session.query(DiseaseGene).filter(DiseaseGene.split==1)\n",
    "sv = SentenceNgramViewer(candidates, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
